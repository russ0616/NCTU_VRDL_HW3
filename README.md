# NCTU_VRDL_HW3
NCTU Visual Recognition using Deep Learning HW3

## Hardware
The following specs were used to create the original solution.

Ubuntu 18.04.3 LTS
Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz
3x GeForce RTX 2080 TI

## Reproducing Submission
To reproduct my submission without retrainig, do the following steps:
1. [Introduction](#Introduction)
2. [Installation](#installation)
3. [Dataset Preparation](#Dataset-Preparation)
4. [Training](#Training) detail.
5. [Testing](#Testing) detail.
6. [Reference](#Reference)

## Introduction
This work is for image instance segmentation, training and evaluate on Tiny PASCOL VOC dataset.
For the model part, I use YOLACT as our backbone. We reference the code generated by [Daniel Bolya](https://github.com/dbolya).
Here's the original code, [yolact](https://github.com/dbolya/yolact).
Also, the paper link of this paper is in the below: [YOLACT Real-time Instance Segmentation](https://paperswithcode.com/paper/yolact-real-time-instance-segmentation)

## Installation
this code was trained and tested with Python 3.7 and Pytorch 1.3.0 (Torchvision 0.4.1) on Ubuntu 18.04
the detail is in the environment.yml file. Just install the environment by the instruction below.

```
conda env create -f environment.yml

python==3.7
  - pip
  - cython 
  - pytorch::torchvision
  - pytorch::pytorch >=1.0.1
  - cudatoolkit
  - cudnn
  - pytorch::cuda100
  - matplotlib
  - git # to download COCO dataset
  - curl # to download COCO dataset
  - unzip # to download COCO dataset
  - conda-forge::bash # to download COCO dataset
```


## Dataset Preparation
I seperate the original training data (1349 images) into two part. One for training (1200 images) and one for evaluating (149 images).
Also, seperate the training annotation file (pascal_train.json) into two part. (pascal_new_train.json and pascal_new_eval.json)
We also have testing data (100 images) for testing.

Put the dataset in ```data/```
All required files in the directory.
```
NCTU_VRDL_HW3
  +- data
  |  +- train_images
     | +- (all images)
  |  +- test_images   
     | +- (all images)
  |  --pascal_new_eval.json
  |  --pascal_new_train.json
  |  --test.json
```
After that, we should create a definition for our dataset under ```dataset_base``` in ```data/config.py```(see the explanation below)

```
my_custom_dataset = dataset_base.copy({
    'name': 'My Dataset',

    'train_images': './data/train_images',
    'train_info':   'pascal_new_train.json',

    'valid_images': './data/train_images',
    'valid_info':   'pascal_new_eval.json',

    'has_gt': True,
    'class_names': PASCAL_CLASSES
})
```
Finally, change the ```dataset``` name under ```yolact_base_config``` into ```my_custom_dataset```.
change the ```num_classes``` under ```yolact_base_config``` into ```len(my_custom_dataset.class_names) + 1```.

## Training
To train models, please download the pretrained weight on imagenet first. Here's the [link](https://github.com/dbolya/yolact).
Choose the weight you'd like to use. For me, I'm using ```resnet101_reducedfc.pth```
run following commands.
```
# Trains yolact_base_config with a batch_size of 20. Using GPU devices id = [0,1]. Allocate 10 batches each to each GPU.
python train.py --config=yolact_base_config --batch_size=20 --batch_alloc=[10,10] --devices=[0,1]
```
The expected training times are:
Model | GPUs | Image size | Training Epochs | Training Time
------------ | ------------- | ------------- | ------------- | -------------
YOLACT | 2x RTX 2080Ti | 500 x 300 | 90 | 1 hours

## Testing
To evaluate models and display the results, run following commands.
```
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15
```
the results will be saved in the ```./results/images/``` directory.

To test models and get the result .json file, run following commands.
```
python createJSON.py
```
After testing the result will be generate in the output folder.

## Reference
1. [YOLACT](https://github.com/dbolya/yolact).
